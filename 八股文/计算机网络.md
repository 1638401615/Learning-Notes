## 基础

* 应用层数据到传输层，若是超过MSS（TCP最大报文段长度），就要将数据包分块，每块称之为一个**TCP段**
* IP协议给传输层报文加IP报文头，如果超过MTU（以太网中一般为1500字节），就再次分块

* 传输层主要服务应用层，帮助实现应用到应用的通信，实际传输功能依靠网络层完成
* IP地址分为**网络号**和**主机号**，用子网掩码和IP地址按位与得到网络号，子网掩码取反按位与IP地址得到主机号
* IP的主要功能：**寻址**和**路由**。**IP 协议的寻址作用是告诉我们去往下一个目的地该朝哪个方向走，路由则是根据「下一个目的地」选择路径。寻址更像在导航，路由更像在操作方向盘**。

## 键入网址的整个流程

### 浏览器解析URL

> 如果URL省略了路径部分，请求的是**默认文件**，也就是 `/index.html` 或者 `/default.html` 这些文件，这样就不会发生混乱了。

### 真实地址查询---DNS

* 浏览器先看**本身**有没有域名的缓存，没有就去问**操作系统**，操作系统看自己的缓存，没有再看**hosts文件**，都没有去问**本地DNS**

* 本地DNS，也就是客户端`TCP/IP`设置里面填写的DNS服务器地址

### 协议栈

DNS获取到IP后，把HTTP传输工作交给操作系统**协议栈**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E9%94%AE%E5%85%A5%E7%BD%91%E5%9D%80%E8%BF%87%E7%A8%8B/7.jpg" alt="img" style="zoom:50%;" />

应用程序（浏览器）通过调用 **Socket 库**，来委托协议栈工作。协议栈的上半部分有两块，分别是负责收发数据的 TCP 和 UDP 协议，这两个传输协议会接受应用层的委托执行收发数据的操作。

协议栈的下面一半是用 IP 协议控制网络包收发操作，在互联网上传数据时，数据会被切分成一块块的网络包，而将网络包发送给对方的操作就是由 IP 负责的。

此外 IP 中还包括 `ICMP` 协议和 `ARP` 协议。

- `ICMP` 用于告知网络包传送过程中产生的错误以及各种控制信息。
- `ARP` 用于根据 IP 地址查询相应的以太网 MAC 地址。

IP 下面的网卡驱动程序负责控制网卡硬件，而最下面的网卡则负责完成实际的收发操作，也就是对网线中的信号执行发送和接收操作。

### 可靠传输---TCP

报文头部

* **源端口号**、**目的端口号**（这里的端口号用于解包的时候服务器得知是哪个进程在监听和需要这个包）
* 包的序号，用于处理乱序问题
* 确认号
* 状态位：`SYN,ACK,FIN,RST`
* 窗口大小，**流量控制**需要（TCP还会做**拥塞控制**，通路是否堵车无能为力，唯一能做的是改变自己发送速度）

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4/%E7%BD%91%E7%BB%9C/TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.drawio.png" alt="TCP 三次握手" style="zoom:50%;" />

**三次握手的目的是保证双方都有收发能力**

MSS是纯纯数据，MTU是带IP头部的网络包最大长度

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E9%94%AE%E5%85%A5%E7%BD%91%E5%9D%80%E8%BF%87%E7%A8%8B/11.jpg" alt="MTU 与 MSS" style="zoom:50%;" />

* HTTP默认端口号80，HTTPS默认端口号443
* TCP首部20个字节不算选项，UDP首部8个字节，IP首部40个字节不算选项

### 远程定位---IP

IP报文：

* 源地址IP和目的地址IP
* 协议号：`06`（十六进制）表示TCP

> 多网卡情况下，源IP地址选择？
>
> 根据**路由表**规则，来判断哪一个网卡作为源地址 IP。如果都不匹配就会选择**默认网关**

### 两点传输---MAC

MAC包头格式：

* 接收方MAC地址（48位）

* 发送方MAC地址（48位）

* 协议类型（16位）：

  - `0800` ： IP 协议
  - `0806` ： ARP 协议

  获取目的MAC地址：

  1. 查一下路由表找到匹配条目，把包发给Gateway列中的IP地址
  2. 根据IP地址，用**ARP协议**查找到路由器MAC地址。（刚开始广播，后面会先查**ARP缓存**）

### 出口---网卡

* 网卡驱动程序控制网卡，把**数字信息转换为电信号**在网线上传输
* 网卡驱动获取网络包之后，会将其**复制**到网卡内的缓存区中，接着会在其**开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列**
* 起始帧分界符是一个用来表示包起始位置的标记
* 末尾的 `FCS`（帧校验序列）用来检查包传输过程是否有损坏

最后网卡会将包转为电信号，通过网线发送出去。

### 送别者---交换机

* 交换机工作在MAC层，属于**二层网络设备**
* **交换机端口不具有MAC地址**
* 交换机里面有个**MAC地址表**，存储**设备的MAC地址**和**该设备连接的端口**，根据这些信息进行转发
* 找不到就群发除了源端口的所有端口，相应包发回来就能记录这个新的地址和端口
* 以下两个属于广播地址：
  - MAC 地址中的 `FF:FF:FF:FF:FF:FF`
  - IP 地址中的 `255.255.255.255`

### 出境大门---路由器

* **路由器**是基于 IP 设计的，俗称**三层**网络设备，路由器的各个端口都具有 MAC 地址和 IP 地址；和交换机区别

* 路由器里面有个**路由表**，把收到的帧拆MAC头部后，根据**拆开后的IP头部**和**路由表**进行包的转发

  路由表存储了：目标IP地址，子网掩码，网关，接口，跃点数。（**目标IP地址是子网地址，要把真的目标地址和子网掩码拿去与运算了再比较。**）

  如果网关是空的，说明接收方IP地址就剩要转发到的目的地址。否则说明还未抵达终点，继续发给路由器转发。

* 实在找不到匹配路由，会选择**默认路由**

* 知道IP之后都需要通过ARP得知MAC地址。

## Linux系统如何收发网络包

* 应用程序通过系统调用和socket层进行数据交互
* Socket层下面就是传输层、网络层和网络接口层
* 最下面一层是网卡驱动程序和硬件网卡设备

下图是Linux网络协议栈的图示：

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%B5%AE%E7%82%B9/%E5%8D%8F%E8%AE%AE%E6%A0%88.png" alt="img" style="zoom:50%;" />



### Linux接收网络包流程

网卡是计算机里的一个硬件，专门负责接收和发送网络包，当网卡接收到一个网络包后，会通过 **DMA 技术**，将网络包写入到指定的内存地址，也就是**写入到 Ring Buffer** ，这个是一个环形缓冲区，接着就会告诉操作系统这个网络包已经到达。

> 如何告诉操作系统数据到达？
>
> * 最简单的方式：**触发中断**，但是高性能网络下可能会频繁中断，影响CPU效率
> *  **NAPI 机制**：混合**中断**和**轮询**的方式接收数据包，核心是**不采用中断方式读取数据**。先采用中断唤醒数据接收的服务程序，然后poll的方法来轮询数据。

### Linux发送网络包流程

首先，应用程序会调用 Socket 发送数据包的接口，由于这个是系统调用，所以会从用户态陷入到内核态中的 Socket 层，内核会申请一个内核态的 sk_buff 内存，**将用户待发送的数据拷贝到 sk_buff 内存，并将其加入到发送缓冲区**。

如果使用TCP要**拷贝一个新的sk_buff副本**，因为sk_buff在后续调用网络层到网卡发送完成的时候会被释放，但是**TCP支持丢失重传**，所以在收到ACK之前sk_buff不能删除。所以内核每次在调用网卡发送，都传递的是sk_buff的一个拷贝。等ACK到了再真正删除。

网络接口层工作准备好后，会触发「**软中断**」告诉网卡驱动程序，这里有新的网络包需要发送，驱动程序会从**发送队列中读取 sk_buff**，将这个 **sk_buff 挂到 RingBuffer** 中，接着将 sk_buff 数据**映射**到网卡可访问的**内存 DMA 区域**，最后触发真实的发送。

当发送完成的时候，网卡设备会触发一个**硬中断来释放内存**，主要是释放 sk_buff 内存和清理 RingBuffer 内存。

> 发送网络数据的时候，涉及几次内存拷贝操作？

* 第一次，调用发送数据的系统调用的时候，内核会**申请一个内核态的 sk_buff 内存**，将用户待发送的数据拷贝到 sk_buff 内存，并将其加入到发送缓冲区。

* 第二次，在使用 **TCP 传输协议**的情况下，从**传输层进入网络层**的时候，每一个 **sk_buff 都会被克隆一个新的副本**出来。副本 sk_buff 会被送往网络层，等它发送完的时候就会释放掉，然后原始的 sk_buff 还保留在传输层，目的是为了实现 TCP 的可靠传输，等收到这个数据包的 ACK 时，才会释放原始的 sk_buff 。

* 第三次，当 **IP 层发现 sk_buff 大于 MTU** 时才需要进行。会再**申请额外的 sk_buff**，并将原来的 sk_buff 拷贝为多个小的 sk_buff。

## TCP vs UDP

[一文搞定 UDP 和 TCP 高频面试题！ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/108822858)

* 传输层提供了**进程间的逻辑通信**，网络层只负责把分组发送到目的主机，真正通信的是主机中的进程。

* TCP和UDP的特点：
  * UDP：无连接，尽可能交付，没拥塞控制，面向报文，支持一对一，一对多多对一和多对多通信
  * TCP：**面向连接**，提供**可靠**交付，有流量控制，拥塞控制，提供全双工通信，**面向字节流**，每条TCP只能是点对点的（一对一）
  * UDP更加适合消息的**多播发布**，从单个点向多个点传输消息。
  
* TCP vs UDP

  * 有无连接

  * 可靠性
  * 有序性
  * 数据边界
  * 速度
  * 发送消耗（报头大小）
  * 拥塞和流量控制

* **TCP首部长度20-60字节（20字节固定首部），UDP首部只有8个字节**

* TCP的确认号是希望收到的下一个报文段的序号

### 拥塞控制 vs 流量控制

拥塞控制：

* 作用于**网络**，防止过多数据注入到网络，避免出现网络负载过大的情况
* 通过拥塞窗口实现

流量控制：

* 解决的是**发送方和接收方速率不匹配**的问题
* 通过滑动窗口实现

流量控制主要是为了保证接收方能够处理发送方的数据，而拥塞控制主要是为了保证网络中的数据不会超过网络的承载能力。

### TCP的三次握手

1. client向server发送连接请求**SYN**报文，SYN=1，ACK=0，选择初始序号x（客户机进入SYN_SEND状态）
2. 服务器接收到请求报文，如果同意建立连接，发回**SYNACK**报文，SYN=1，ACK=1，确认号x+1,同时选择初始序号y（服务器进入SYN_RECV状态）
3. 客户端接收到服务器的连接确认报文后，发送**ACK for SYNACK**，确认号y+1，序号x+1，服务器收到后连接建立（客户端和服务端都进入ESTABLISH状态）

> 为什么要第三次握手？
>
> 1. 防止失效连接请求到达服务器导致服务器错误打开连接
> 2. 服务端和客户端都能保证双方的收发能力正常

### TCP的四次挥手

1. 客户端发送**FIN**，包含一个ACK表示确认对方最近一次发过来的数据，包含一个当前序列号K
2. 服务端把K+1作为ACK序列号，发回**对FIN的ACK报文**，上层应用程序会被告知另一端发起了关闭操作，通常将引起应用程序发起自己的关闭操作
3. 服务端发起自己的**FIN**，ACK=K+1，Seq=L
4. 客户端确认，进入**TIME-WAIT**状态，等待2 MSL（最大报文存活时间）后释放连接，ACK=L+1

> 为什么要四次挥手关闭连接？
>
> * 服务端收到客户端FIN，说明客户端想要断开连接，但是服务端仍有数据，等到发送完所有数据，才会发送FIN关闭此方向的连接，连接接收方发送ACK确认关闭连接。
> * **接收到对方的FIN报文，只能表示对方不再发送数据了但是还能接收数据**
>
> 接收到FIN只能返回ACK，不能返回FIN？
>
> * 因为结束数据传输的指令是上层应用层给出的
>
> 为什么需要一个TIME-WAIT状态？（客户端收到服务器端的FIN进入此状态）
>
> * 确保最后一个确认报文能到达，如果服务端没收到客户端发来的确认报文，就会重新发送FIN报文，所以需要客户端等待一段时间，确保服务端没收到ack的时候重发的fin能被客户端收到
> * 一般长度为`2MSL`（MSL：最大报文段生存时间），让本连接持续时间内产生的所有报文都从网络中消失，使得下一个连接不会出现旧的连接请求报文

## 路由

* 静态路由和动态路由

* 路由协议算法：

  * 距离向量法：RIP、IGRP
  * 链路状态法：OSPF、IS-IS

  

HTTP和TCP的keep-alive

* HTTP是为了一次TCP连接可以持续发送多次数据，减少TCP连接的建立次数
* TCP是为了检测空闲链接是否已断开，过一段时间发数据为空的探测报文去查看对面关闭了没。

服务器怎么判断客户端断开链接：

1. TCP的keep-alive：多次尝试没有回答就断开，**周期有点长**
2. 应用层的**heart-beat**：可以很快决定链接是否中断，且由于在应用层，还能定义中断后行为，TCP那个只能自动丢弃



端到端 vs 点到点

* 端到端：传输层概念，发送端到接收端，是点到点的基础上的高一级通信方式，由一段段点到点构成，完成应用程序之间的通信

  优点：

  * 链路建立连接后，发送端知道接收端一定能收到，经过中间设备不用储存转发，传输延迟小

  缺点：

  * 知道接收端收到数据，发送端设备要一直参与传输。浪费发送方设备
  * 接收设备关机或者故障，端到端传输不可能实现

* 点到点：数据链路层或者网络层、 点对点是基于MAC地址和或者IP地址，是指一个设备发数据给与该这边**直接连接的其他设备**，这台设备又在合适的时候将数据传递给与它相连的下一个设备，通过一台一台直接相连的设备把数据传递到接收端。

  缺点：

  * 发出数据不知道接收端能否收到，何时收到

  优点：

  * 发送端发送后无需参与后续流程，不会浪费资源
  * 接收端关机故障，点到点传输也能用存储转发技术进行缓冲

**IP及以下各层采用点到点传输，4层以上采用端到端传输**



### Get vs Post

1. GET请求在URL中传送的参数是有长度限制的，而POST没有。
2. GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息。
3. GET参数通过URL传递，POST放在Request body中。
4. GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留。
5. GET请求只能进行url编码，而POST支持多种编码方式。
6. GET请求会被浏览器主动cache，而POST不会，除非手动设置。
7. GET产生的URL地址可以被Bookmark，而POST不可以。
8. GET在浏览器回退时是无害的，而POST会再次提交请求。

### Cookie vs Session

* Cookie在**浏览器**上，Session数据在**服务器**上
* **Cookie不是很安全，Session比较安全**
* Session会在一定时间内保存在服务器上，访问增多会比较占用服务器性能，**考虑减轻服务器负担的情况，用Cookie**

* 单个Cookie不能超过4K，很多浏览器限制一个网站最多保存20个Cookie



## HTTP vs RPC

* RPC定制化程度更高，可以采用体积更小的序列化协议去保存结构体数据，也无需像HTTP考虑各种浏览器行为，如重定向等，所以性能会好一些。
* HTTP则使用Json来序列化结构体数据，会有冗余
* 以上二者基于HTTP1.1，HTTP2性能可能比很多RPC都好，gRPC的底层就是HTTP2，但是2015年才出来，基于历史原因很少使用。

* HTTP主要用于B/S结构，RPC用于C/S结构。但是在逐渐融合了。很多软件支持多端，所以对外一般使用HTTP协议，而内部集群的微服务之间则采用RPC协议进行通讯。



## HTTP keepalive vs TCP keepalive

* HTTP 的 Keep-Alive 也叫 HTTP 长连接，该功能是由「应用程序」实现的，可以使得用**同一个 TCP 连接来发送和接收多个 HTTP 请求/应答**，**减少**了 HTTP 短连接带来的**多次 TCP 连接建立和释放的开销**。
* TCP 的 Keepalive 也叫 **TCP 保活机制**，该功能是由「内核」实现的，当客户端和服务端长达一定时间没有进行数据交互时，内核为了确保该连接是否还有效，就会发送**探测报文**，来检测对方是否还在线，然后来决定是否要关闭该连接。



## HTTP特性

### HTTP/1.1

* 优点：简单，灵活，易于扩展，应用广泛，跨平台

* 缺点：无状态，明文传输，不安全（明文、不验证通信方身份，无法证明报文完整性）

  > 不安全的例子：
  >
  > 1. 明文传输，内容被窃听
  > 2. 不验证身份，可能遭遇伪装，访问假的网站
  > 3. 无法证明报文完整性，报文可能遭到篡改，网页被植入垃圾广告等

* 性能：长连接（解决了1.0的连接问题），管道网络传输（请求发送pipeline），没解决**响应的队头阻塞**，请求/响应头部不压缩，浪费多，没有请求优先级控制，只能从客户端开始请求。

### HTTPS

* 在HTTP和TCP之间加了 **SSL/TLS** 协议，实现了：

  * 信息加密：交互信息无法窃取，利用**混合加密**实现
  * 校验机制：无法篡改通信内容，利用**摘要算法**为数据生成独一无二的”指纹“
  * 身份证书：证明网站真实性，把**服务器公钥放入数字证书**，解决冒充风险

  非对称加密交换密钥，通信用对称加密。此为**混合加密**，对称速度快但是不安全，非对称安全但是速度慢

> 非对称密钥算法的不同应用
>
> - **公钥加密，私钥解密**。这个目的是为了**保证内容传输的安全**，因为被公钥加密的内容，其他人是无法解密的，只有持有私钥的人，才能解密出实际的内容；
> - **私钥加密，公钥解密**。这个目的是为了**保证消息不会被冒充**，因为私钥是不可泄露的，如果公钥能正常解密出私钥加密的内容，就能证明这个消息是来源于持有私钥身份的人发送的。
>
> 数字签名算法：哈希算法只能保证内容不会被篡改，**但是并不能保证「内容 + 哈希值」不会被中间人替换，因为这里缺少对客户端收到的消息是否来源于服务端的证明**。**数字签名**算法就可以实现身份证明。
>
> * **私钥加密摘要哈希值，就是数字签名**
>
> <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/%E6%95%B0%E5%AD%97%E7%AD%BE%E5%90%8D.png" alt="img" style="zoom:50%;" />

* 数字证书

  - 可以通过哈希算法来保证消息的完整性；
  - 可以通过数字签名来保证消息的来源可靠性（能确认消息是由持有私钥的一方发送的）；

  但是这还远远不够，**还缺少身份验证的环节**，万一公钥是被伪造的呢？

  需要把「个人信息 + 公钥 + 数字签名」打包成一个**数字证书**，注册到权威机构，这里的数字签名是权威机构对服务器公钥做的数字签名

  <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/22-%E6%95%B0%E5%AD%97%E8%AF%81%E4%B9%A6%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png" alt="数子证书工作流程" style="zoom: 67%;" />

* TLS的流程：

  1. 客户端发一个随机数过去，顺便说一下支持的TLS协议和支持的密码套件列表，如RSA加密算法
  2. 服务端发一个随机数回来，顺便发一个证书验证一下身份，确认TLS版本协议和密码套件列表
  3. 客户端用服务端公钥加密第三个随机数**pre-master**，发回给服务端。
  4. 两端都有三个随机数，用协商好的加密算法生成本次通信的会话密钥

  至此，TLS握手结束，进入会话密钥对称加密通信

* CA签发证书过程：

  1. CA把持有者的**公钥、用途、颁发者、有效时间等**打包，对这些信息进行hash
  2. CA用自己的**私钥加密hash值**，生成签名
  3. 把签名添加在文件证书上（就是本身的包），形成数字证书

* 客户端验证数字证书：

  1. 同样的hash算法获取证书hash值H1，用CA公钥解密获取Hash值H2，对比一下值相同就是可信赖的

  <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/%E8%AF%81%E4%B9%A6%E7%9A%84%E6%A0%A1%E9%AA%8C.png" alt="img" style="zoom: 50%;" />

### HTTP/2

* 基于HTTPS，安全有保障
* 头部压缩
* 二进制格式
* 并发传输，一个TCP连接包含多个Stream，Stream里可以包含一个或者多个Message（HTTP1里面的请求或者响应）

* 服务器推送：服务器可以主动给客户端发送消息

缺点：

* 基于TCP，所以还是存在“队头阻塞”

### HTTP/3

* 为了解决队头阻塞，**HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！**

基于 UDP 的 **QUIC 协议** 可以实现类似 TCP 的可靠性传输。

QUIC 有以下 3 个特：

- 无队头阻塞：**当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题**

- 更快的连接建立： HTTP/3 的 QUIC 协议并不是与 TLS 分层，而是 **QUIC 内部包含了 TLS**，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS/1.3，因此仅需 **1 个 RTT 就可以「同时」完成建立连接与密钥协商**

  ![TCP HTTPS（TLS/1.3） 和 QUIC HTTPS ](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/28-HTTP3%E4%BA%A4%E4%BA%92%E6%AC%A1%E6%95%B0.png)

- 连接迁移：基于TCP的话，TCP连接是一个四元组确定的（源地址，源端口，目的地址，目的端口），**当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立连接**。

  QUIC用的**连接ID**标记通信两个端点，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了**连接迁移**的功能。

## TCP

**面向连接，基于字节流，可靠**

什么是连接：用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括 **Socket、序列号和窗口大小**称为连接。

:star: 为什么需要三次握手？

- 三次握手才可以阻止重复历史连接的初始化（主要原因）

  两次握手，**服务端没有中间状态给客户端来阻止历史连接，导致服务端可能建立一个历史连接，造成资源浪费**。

- 三次握手才可以同步双方的初始序列号

- 三次握手才可以避免资源浪费

  两次握手收到一个SYN服务端建立一个连接，要是客户端SYN阻塞重复发很多个SYN，就会建立很多个无效的冗余连接，造成资源浪费



* **ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的报文**。

:star:为什么需要TIME_WAIT状态？

* 防止历史连接数据被后面连接错误接收
* 保证 被动关闭连接 的一方，能被正确地关闭
